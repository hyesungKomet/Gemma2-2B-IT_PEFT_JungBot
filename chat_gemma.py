import streamlit as st
from dotenv import load_dotenv
import os
import torch
from huggingface_hub import login
from gemma_bot import JungBot

# í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ë¡œë“œ
load_dotenv()

# ì„¸ì…˜ ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€ (ë””ë²„ê¹…ìš©)
if st.button("ì„¸ì…˜ ì´ˆê¸°í™”"):
    st.session_state.clear()
    st.write("ì„¸ì…˜ ì´ˆê¸°í™”ë¨")

# ì„¸ì…˜ ìƒíƒœì— í† í°ì´ ì—†ìœ¼ë©´ ì…ë ¥ í•„ë“œ í‘œì‹œ
if "hf_token" not in st.session_state:
    hf_token = st.text_input("Hugging Face Token", type="password")
    if hf_token:
        st.session_state.hf_token = hf_token
        login(token=hf_token)
        st.success("Logged in successfully!")
else:
    # ì„¸ì…˜ ìƒíƒœì— í† í°ì´ ìˆìœ¼ë©´ ì‚¬ìš©
    hf_token = st.session_state.hf_token
    login(token=hf_token)

def save_chat(user_input, model_output):
    st.session_state.chat_history.append({'user': user_input, 'model': model_output})

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
    st.write('chat_history loaded!')

if "model" not in st.session_state:
    st.session_state.model = JungBot(modelName='google/gemma-2-2b-it')
    st.write('Gemma Model loaded into session state!')

print('gemma model loaded!')

st.title("ğŸ’¬ Jung Bot - Talk to AI mentalist!")

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Feel free to talk to me!"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

prompt = st.chat_input("ì—¬ê¸°ì— ì…ë ¥í•´ì£¼ì„¸ìš”!")

if prompt:
    print('prompt: ', prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # ì‚¬ìš©ì ì…ë ¥ ì „ì²˜ë¦¬
    clean_prompt = prompt.strip().lower().rstrip('.')

    response = st.session_state.model.inference(clean_prompt, st.session_state.chat_history)
    print('response: ', response)
    if response == 0:
        save_chat(prompt, response)
        st.success('Chat report saved successfully.')
        st.stop()
    else:
        msg = response if response else 'No response from the model'

    # ì‘ë‹µ í›„ì²˜ë¦¬ ë° ì¤„ë°”ê¿ˆ ì²˜ë¦¬
    msg = msg.replace('\n', '\n\n').strip()  # ë‘ ì¤„ ë„ìš°ê¸° ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": msg})

    st.chat_message("assistant").write(msg)